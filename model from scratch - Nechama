{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "1tTzvc2u2vVLkZNnm__4iJKQeIO_t2isW",
      "authorship_tag": "ABX9TyMfzvwZ+xVyZZgrlhNVWhLB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2022Group3/2022Group3/blob/main/model%20from%20scratch%20-%20Nechama\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "# from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "99V5KVT0PN15"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def extract_zip():\n",
        "\t# load dataset\n",
        "  file=np.load(r\"drive/MyDrive/data_modified.npz\")\n",
        "  data_npz = dict(zip((\"{}\".format(k) for k in file), (file[k] for k in file)))\n",
        "\t# one hot encode target values\n",
        "\t# trainY = to_categorical(trainY)\n",
        "\t# testY = to_categorical(testY)\n",
        "  return data_npz['train'], data_npz['ytrain'], data_npz['validation'], data_npz['yvalidation'], data_npz['test'], data_npz['ytest']"
      ],
      "metadata": {
        "id": "GuTTAhRKHFnl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "  trainX, trainY, validationX, vlidationY, testX, testY = extract_zip()\n",
        "  return trainX, to_categorical(trainY), validationX, to_categorical(vlidationY), testX, to_categorical(testY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bmaw6xlyMHzl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX, trainY, validationX, vlidationY, testX, testY = load_dataset()\n",
        "print(f'trainx= {trainX} , trainy= {trainY}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ZAJFIXC9M0",
        "outputId": "c8b1a464-634d-4fc5-d3e0-08c273998968"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainx= [[[[ 21  57  95]\n",
            "   [ 21  58  98]\n",
            "   [ 20  59 101]\n",
            "   ...\n",
            "   [ 26  34  46]\n",
            "   [ 26  35  49]\n",
            "   [ 29  39  56]]\n",
            "\n",
            "  [[ 20  55  91]\n",
            "   [ 20  56  94]\n",
            "   [ 19  57  97]\n",
            "   ...\n",
            "   [ 39  44  53]\n",
            "   [ 25  33  46]\n",
            "   [ 22  35  53]]\n",
            "\n",
            "  [[ 18  52  86]\n",
            "   [ 18  53  89]\n",
            "   [ 18  55  93]\n",
            "   ...\n",
            "   [ 35  41  53]\n",
            "   [ 24  34  49]\n",
            "   [ 24  40  57]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[231 231 233]\n",
            "   [242 242 242]\n",
            "   [230 228 226]\n",
            "   ...\n",
            "   [ 27  37  41]\n",
            "   [ 29  37  37]\n",
            "   [ 30  38  44]]\n",
            "\n",
            "  [[181 178 179]\n",
            "   [209 205 203]\n",
            "   [192 187 183]\n",
            "   ...\n",
            "   [ 23  35  40]\n",
            "   [ 31  37  37]\n",
            "   [ 35  37  41]]\n",
            "\n",
            "  [[126 131 133]\n",
            "   [102 104 105]\n",
            "   [ 63  64  63]\n",
            "   ...\n",
            "   [ 25  35  46]\n",
            "   [ 32  37  42]\n",
            "   [ 35  38  44]]]\n",
            "\n",
            "\n",
            " [[[114 110 122]\n",
            "   [113 109 123]\n",
            "   [110 105 121]\n",
            "   ...\n",
            "   [ 71  72  74]\n",
            "   [ 37  36  38]\n",
            "   [ 62  61  63]]\n",
            "\n",
            "  [[116 112 122]\n",
            "   [109 105 117]\n",
            "   [113 109 122]\n",
            "   ...\n",
            "   [ 57  60  64]\n",
            "   [ 43  42  44]\n",
            "   [ 43  42  44]]\n",
            "\n",
            "  [[118 115 123]\n",
            "   [120 116 126]\n",
            "   [117 112 124]\n",
            "   ...\n",
            "   [ 44  48  54]\n",
            "   [ 47  48  50]\n",
            "   [ 45  45  47]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 62  63  69]\n",
            "   [132 144 151]\n",
            "   [ 59  78  82]\n",
            "   ...\n",
            "   [ 68  79  79]\n",
            "   [ 34  41  44]\n",
            "   [ 23  29  33]]\n",
            "\n",
            "  [[117 122 131]\n",
            "   [130 142 152]\n",
            "   [ 32  49  57]\n",
            "   ...\n",
            "   [ 93 103 103]\n",
            "   [ 83  90  93]\n",
            "   [ 37  44  48]]\n",
            "\n",
            "  [[117 126 137]\n",
            "   [107 121 133]\n",
            "   [ 35  51  61]\n",
            "   ...\n",
            "   [ 97 108 107]\n",
            "   [115 122 125]\n",
            "   [ 64  70  75]]]\n",
            "\n",
            "\n",
            " [[[ 73 100  62]\n",
            "   [ 67  96  55]\n",
            "   [ 64  99  53]\n",
            "   ...\n",
            "   [ 70 112  37]\n",
            "   [ 58  99  42]\n",
            "   [ 62 101  58]]\n",
            "\n",
            "  [[ 67  97  50]\n",
            "   [ 56  89  39]\n",
            "   [ 58  95  42]\n",
            "   ...\n",
            "   [ 68 107  45]\n",
            "   [ 60 100  49]\n",
            "   [ 67 105  64]]\n",
            "\n",
            "  [[ 60  93  36]\n",
            "   [ 53  89  31]\n",
            "   [ 57  97  38]\n",
            "   ...\n",
            "   [ 73 109  62]\n",
            "   [ 71 108  66]\n",
            "   [ 71 108  69]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[107 152 109]\n",
            "   [ 95 139  99]\n",
            "   [ 88 132  92]\n",
            "   ...\n",
            "   [ 83 121 104]\n",
            "   [122 161 141]\n",
            "   [117 159 131]]\n",
            "\n",
            "  [[117 159 111]\n",
            "   [100 142 102]\n",
            "   [ 95 138  98]\n",
            "   ...\n",
            "   [ 99 136 135]\n",
            "   [123 158 154]\n",
            "   [126 165 150]]\n",
            "\n",
            "  [[106 148  99]\n",
            "   [ 98 139  98]\n",
            "   [ 99 142 102]\n",
            "   ...\n",
            "   [117 156 155]\n",
            "   [130 171 169]\n",
            "   [139 184 170]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[224 221 216]\n",
            "   [239 237 232]\n",
            "   [248 247 244]\n",
            "   ...\n",
            "   [249 249 244]\n",
            "   [241 239 231]\n",
            "   [231 227 220]]\n",
            "\n",
            "  [[222 218 213]\n",
            "   [233 231 225]\n",
            "   [247 246 241]\n",
            "   ...\n",
            "   [249 248 243]\n",
            "   [237 235 228]\n",
            "   [228 225 218]]\n",
            "\n",
            "  [[228 226 220]\n",
            "   [236 234 229]\n",
            "   [250 249 245]\n",
            "   ...\n",
            "   [250 249 245]\n",
            "   [241 239 232]\n",
            "   [236 234 227]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 41  61  40]\n",
            "   [ 48  67  45]\n",
            "   [ 50  73  48]\n",
            "   ...\n",
            "   [ 91  99 111]\n",
            "   [ 90  99 110]\n",
            "   [ 85  93 103]]\n",
            "\n",
            "  [[ 37  58  34]\n",
            "   [ 46  69  46]\n",
            "   [ 52  80  55]\n",
            "   ...\n",
            "   [ 93 100 114]\n",
            "   [ 90  97 109]\n",
            "   [ 84  90 100]]\n",
            "\n",
            "  [[ 44  69  50]\n",
            "   [ 59  85  80]\n",
            "   [ 70  91  98]\n",
            "   ...\n",
            "   [ 92  99 113]\n",
            "   [ 89  96 108]\n",
            "   [ 84  87  98]]]\n",
            "\n",
            "\n",
            " [[[ 84 127 100]\n",
            "   [ 70 103  80]\n",
            "   [ 57  87  65]\n",
            "   ...\n",
            "   [ 69 118  86]\n",
            "   [ 61 137 100]\n",
            "   [ 64 132  98]]\n",
            "\n",
            "  [[ 84 125  98]\n",
            "   [ 74 105  81]\n",
            "   [ 65 102  77]\n",
            "   ...\n",
            "   [ 69 138 100]\n",
            "   [ 71 143 109]\n",
            "   [ 72 135 102]]\n",
            "\n",
            "  [[ 75 109  83]\n",
            "   [ 67  98  73]\n",
            "   [ 67 118  90]\n",
            "   ...\n",
            "   [ 66 138 102]\n",
            "   [ 82 141 111]\n",
            "   [ 80 134 103]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 57 101 139]\n",
            "   [ 68 111 148]\n",
            "   [ 85 122 155]\n",
            "   ...\n",
            "   [ 99 187 149]\n",
            "   [ 99 187 146]\n",
            "   [ 96 186 145]]\n",
            "\n",
            "  [[ 66 111 151]\n",
            "   [ 68 111 150]\n",
            "   [ 97 132 162]\n",
            "   ...\n",
            "   [ 99 190 153]\n",
            "   [102 190 151]\n",
            "   [103 191 151]]\n",
            "\n",
            "  [[ 74 114 147]\n",
            "   [ 78 114 146]\n",
            "   [129 157 179]\n",
            "   ...\n",
            "   [100 189 150]\n",
            "   [100 187 148]\n",
            "   [103 186 147]]]\n",
            "\n",
            "\n",
            " [[[  1   0   0]\n",
            "   [  5   7   7]\n",
            "   [ 54  63  69]\n",
            "   ...\n",
            "   [119 144 148]\n",
            "   [ 96 128 134]\n",
            "   [ 85 122 130]]\n",
            "\n",
            "  [[  1   0   0]\n",
            "   [  5  10   9]\n",
            "   [ 85  96 102]\n",
            "   ...\n",
            "   [134 148 156]\n",
            "   [102 125 135]\n",
            "   [ 74 107 115]]\n",
            "\n",
            "  [[  1   0   0]\n",
            "   [  5   8   8]\n",
            "   [ 93  99 104]\n",
            "   ...\n",
            "   [171 175 182]\n",
            "   [164 169 177]\n",
            "   [147 157 164]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[217 226 233]\n",
            "   [177 189 201]\n",
            "   [158 173 186]\n",
            "   ...\n",
            "   [238 241 246]\n",
            "   [238 241 246]\n",
            "   [240 243 248]]\n",
            "\n",
            "  [[219 227 234]\n",
            "   [197 207 220]\n",
            "   [168 190 203]\n",
            "   ...\n",
            "   [238 241 246]\n",
            "   [238 241 245]\n",
            "   [241 244 248]]\n",
            "\n",
            "  [[234 238 244]\n",
            "   [224 229 237]\n",
            "   [208 219 227]\n",
            "   ...\n",
            "   [240 242 243]\n",
            "   [239 241 243]\n",
            "   [243 245 246]]]] , trainy= [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tPctj-ajNyj2"
      },
      "outputs": [],
      "source": [
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(16, activation='softmax'))\n",
        " \t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "IE81FEJBO0lr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()"
      ],
      "metadata": {
        "id": "cAupcXLUO1-K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY,validationX, vlidationY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\t# fit model\n",
        "\tsteps = int(trainX.shape[0] / 64)\n",
        "\thistory = model.fit(it_train, steps_per_epoch=steps, epochs=400, validation_data=(validationX, vlidationY), verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=1)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\t# summarize_diagnostics(history)"
      ],
      "metadata": {
        "id": "RsRQH6orD4cF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "b-7HW3ZNRv6X",
        "outputId": "74e4e211-e6db-4585-a5c9-f43e8b3794a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "703/703 [==============================] - 25s 34ms/step - loss: 2.6326 - accuracy: 0.2258 - val_loss: 1139.3348 - val_accuracy: 0.0584\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ac6c88879450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# entry point, run the test harness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_test_harness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-412bedf78997>\u001b[0m in \u001b[0;36mrun_test_harness\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidationX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlidationY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZBZiRlpTR2UW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}